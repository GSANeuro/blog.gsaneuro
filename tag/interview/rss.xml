
---
layout: atom
title: nil
---

	<item>
	  <title>Peer Support Program for graduate neuroscience students at McGill: an interview with Daniel Almeida</title>
	  <link>//2017/03/16/peer-support-program/</link>
	  <author></author>
	  <pubDate>2017-03-16T06:01:00-04:00</pubDate>
	  <guid>//2017/03/16/peer-support-program/</guid>
	  <description><![CDATA[
	     <blockquote>
  <p>The <a href="https://gsaneuro.com/peer-support/"><strong>GSAN Peer Support program</strong></a> is organized by and for IPN students as additional resource of psychological support available for graduate students on campus. <a href="https://blog.gsaneuro.com/editors/"><strong>Anastasia Glushko</strong></a> talked to Daniel Almeida, GSAN’s Psychological Wellbeing Officer, about the mechanics of the program and the role of peer support in graduate studies.</p>
</blockquote>

<hr />

<p><strong>Anastasia (A): For a start, what is the peer support program? Why do you think that graduate students and specifically IPN students need it?</strong></p>

<p><strong>Daniel (D)</strong>: GSAN’s Peer Support Program is based on a “peers helping peers” design, such that our active listeners are themselves IPN graduate students who share a similar body of experiences as the peers they support.<br />
I’m a firm believer in the idea that anyone regardless of their age, race, gender, social class, or education level can benefit from some form of social support. The literature is clear, social support can both create a psychological barrier between the self and stress as well as equip us with better coping mechanisms for managing stress. Both anecdotal and scientific evidence speak to the strain that graduate school has on our psychological wellbeing. Graduate students experience significant amounts of stress, anxiety, depression, hopelessness, and a sense of the lack of control. I don’t think that we need to consult the literature to understand the deep sense of truth tied to these experiences. That’s the beauty of a peers helping peers program, we understand what our peers are going through because we’ve gone through it are are still going through it ourselves.</p>

<blockquote>
  <p>That’s the beauty of a peers helping peers program, we understand what our peers are going through because we’ve gone through it and are still going through it ourselves.</p>
</blockquote>

<p>Our program is unique, in the sense that I’m not familiar with any other graduate based peer support program. I don’t think that this it’s the case of IPN students being a select breed of graduate students who require more support than other departments, but rather a large portion of us study the neuroscience of mental health and have devoted our lives to the cause. The evolution of the program has been lead by graduate students who are passionate about the psychological wellbeing of our colleagues.</p>

<p>I think that every graduate student at McGill should have a peer support system available to them. This is however unfortunately not the case and is something we’re open to collaborating on with other graduate departments who’d like to use our program as a way to model their own. What I do think is important is having graduate students in the same department who have gone through similar experiences and know our program inside out. For instance, individuals requesting support may want to discuss their fears related to the candidacy exam or procrastination regarding their master’s thesis proposal.</p>

<hr />
<p><strong>A: Can you give me a couple of examples of situations, in which graduate students seek peer support?</strong></p>

<p><strong>D</strong>: I can’t give specific situations of students requesting support since our services are entirely confidential, even to myself as co-director. But, if you can think of something that might concern a graduate student and their psychological wellbeing, then that’s something our active listeners are willing to help a peer through. The beautiful thing about the program is that our active listeners are trained in a wide variety of topics.</p>

<hr />
<p><strong>A: How does the process of getting peer support work? Whom should the student interested in getting peer support contact? How many meetings are there typically? Where do they happen? How are supporters matched with the students who seek peer support?</strong></p>

<p><strong>D</strong>: Student can request support by filling out our google doc on GSAN’s website, which you can access here: https://gsaneuro.com/peer-support/. Meetings are arranged between the active listener and the student requesting support. Active listeners are matched based off of preference for location and gender of the active listener.</p>

<table>
  <tbody>
    <tr>
      <td><img src="/assets/images/peer-support-gsan.png" width="85%" /></td>
    </tr>
    <tr>
      <td><em>Screenshot of the peer support request form from the <a href="https://gsaneuro.com/peer-support/" target="_blank">GSAN website</a></em></td>
    </tr>
  </tbody>
</table>

<hr />
<p><strong>A: How are peer supporters trained in active listening?</strong></p>

<p><strong>D</strong>: Our peer support program has an extensive collection of training opportunities. Every member must attend our three our Active Listening and Support Training taught by myself and my co-officer. The workshop is a combination of theory and practice. We also offer elective training in advanced material, including suicide intervention, supporting a disclosure of sexual assault, STI and HIV support, self-care, sexuality sensitivity training, mental illness awareness, cross-cultural sensitivity training, and achieving mindfulness. We’re always open to hosting other trainings and collaborating with other community groups that can expand the diversity of the trainings we offer. As an incentive to attend more trainings, our active listeners can receive a certificate of advanced training in peer support after attending 4 or more trainings.</p>

<hr />
<p><strong>A: How does a person become a peer supporter?</strong></p>

<p><strong>D</strong>: We’re currently working on a form to upload to GSAN’s site under the “Get Involved” tab. Once we have enough students interested in becoming active listeners we’ll hold the Active Listening and Support Training. We usually run this once a semester. Thus far we have approximately 20 active listeners.</p>

	  ]]></description>
	</item>

	<item>
	  <title>Silencing pain with light: an interview with Ihab Daou</title>
	  <link>//2016/08/22/ihab-daou-ipn-interview/</link>
	  <author></author>
	  <pubDate>2016-08-22T15:01:00-04:00</pubDate>
	  <guid>//2016/08/22/ihab-daou-ipn-interview/</guid>
	  <description><![CDATA[
	     <blockquote>
  <p>The NeuroBlog is interviewing again! We’re excited to have the opportunity of speaking with <a href="https://www.researchgate.net/profile/Ihab_Daou"><strong>Ihab Daou</strong></a>, an accomplished PhD student in <a href="http://apps.mni.mcgill.ca/research/seguela/"><strong>Dr. Philippe Seguela’s lab</strong></a> at the Montreal Neurological Institute. In February 2016, Ihab first-authored an article describing a novel transgenic mouse model in which terminals of primary nociceptive fibers can be silenced using optogenetic techniques. In their study, Ihab and his colleagues were able to highlight the role of peripheral neuronal inputs in the onset and maintenance of pain hypersensitivity, and support the involvement of Na<sub>v</sub>1.8<sup>+</sup> afferents in inflammatory and neuropathic pain. They have been able to “silence” fibers classically associated with pain in mice. They believe this non-invasive model will facilitate drug development for pain therapeutics. <a href="https://blog.gsaneuro.com/editors/"><strong>Shannon Tansley</strong></a> had the opportunity to speak with Ihab about his research.</p>
</blockquote>

<hr />

<h2><i>Pain relief using optogenetics: how does it work?</i></h2>

<p><strong>Shannon (S): Thank you for having found the time to do this interview. Can you tell us how you were able to produce an analgesic effect in animals?</strong></p>

<p><strong>Inab (I)</strong>: Painful stimuli are normally detected by a specialized group of sensory neurons called nociceptors. In order to block pain transmission from the periphery to the central nervous system, we genetically delivered the inhibitory pumps Archaerhodopsin-3 (Arch) to peripheral nociceptors. Arch pumps are activated by orange-yellow light. Since the peripheral nociceptive terminals innervate the superficial layers of the skin, transdermal illumination was sufficient to activate the inhibitory pumps, decrease neuronal activity, reduce nociceptive transmission and therefore produce pain relief.<br /></p>

<table>
  <tbody>
    <tr>
      <td><img src="/assets/images/ihab.png" width="70%" /></td>
    </tr>
    <tr>
      <td><em>Inab Daou in Montreal</em></td>
    </tr>
  </tbody>
</table>

<hr />

<h2><i>The striking advantages of optogenetics in studying pain</i></h2>

<p><strong>S: Optogenetics is becoming increasingly popular for purposes that are typically addressed with pharmacological or genetic measures. Why do you think this novel optogenetic tool is important for pain research and is it implementable in future experiments?</strong></p>

<p><strong>I</strong>: Pharmacological approaches lack temporal control over drug activity, and deficiency in target specificity can lead to severe side effects. On the other hand, genetic tools such as knockouts and ablation strategies do not account for compensation at the cellular and circuit levels.<br />
An optogenetic approach can overcome these limitations by providing a high spatial and temporal control over neuronal activity. Its temporal precision is conferred by the nature of light and the fast kinetics of the opsins. Spatially, optogenetics allows the modulation of particular groups of neurons through specific genetic targeting as well as local light delivery.<br />
We have shown bidirectional optogenetic modulation of peripheral afferents, which is instrumental in the future investigation of sensory neurons in the different stages of inflammatory, neuropathic, and cancer pain.</p>

<p><strong>S: Why do you think these Arch-negative afferents play an important role in the onset and maintenance of pain hypersensitivity?</strong></p>

<p><strong>I:</strong> There is evidence that non-nociceptive low-threshold sensory fibers are involved in mediating pain hypersensitivity under chronic conditions. Since our genetic strategy mainly targets nociceptors, we can predict that a subset of primary afferents involved in mediating pain signals does not express Arch pumps and is therefore unaffected by the optical stimulation. This could explain the partial analgesic effects that we detect in our inflammatory and neuropathic models.</p>

<hr />

<h2><i>Optogenetics beyond basic science: a look into the future</i></h2>

<p><strong>S: Do you believe that optogenetics has a role outside of basic research?</strong></p>

<p><strong>I:</strong> The optogenetic approach is a non-invasive and highly precise method to modulate pain. It confers a previously unachieved spatiotemporal accuracy that overcomes the spatial and temporal limitations of pharmacological drugs.<br />
Currently, the translation of this technology to humans is hampered by the delivery of transgenic opsins to the nervous system. Viral delivery would be the most suited approach, where opsins can be packaged into viruses and viral expression can be genetically restricted to specific neuronal populations ensuring high cellular selectivity.<br />
Regarding opsin activation, wireless light delivery devices have been developed and successfully tested in rodents to optogenetically control neuronal activity. Such devices can be adapted to humans to achieve safe optical stimulations.</p>

	  ]]></description>
	</item>

	<item>
	  <title>Your brain on biased decision-making&#58; an interview with Avinash Vaidya</title>
	  <link>//2016/07/06/avinash-vaidya-ipn-interview/</link>
	  <author></author>
	  <pubDate>2016-07-06T15:01:00-04:00</pubDate>
	  <guid>//2016/07/06/avinash-vaidya-ipn-interview/</guid>
	  <description><![CDATA[
	     <blockquote>
  <p>In our latest post, we introduce you to some very recent research conducted by Avinash Vaidya, who has just defended his Ph.D. thesis in <a href="https://www.mcgill.ca/decisionlab/home-page">Dr. Lesley Fellows’</a> lab at the Montreal Neurological Institute. Avinash worked with patients with frontal lobe lesions on topics related to decision-making. His <a href="http://www.nature.com/ncomms/2015/151214/ncomms10120/full/ncomms10120.html">first-authored paper in Nature Communications</a> investigates the neural circuitry underlying fixation-based value updating. In other words, Avinash investigated the fact that people are more likely to choose options that they have looked at (fixated) for a longer period of time, even if those options were perceived as less appealing initially.<br />
<br />Avinash and Dr. Fellows found that in individuals with damaged dorsomedial prefrontal cortex (PFC), this bias was significantly increased. This allowed them to conclude that the potential role of this brain area is in maintaining unattended values during decision-making. At the same time, other patient groups— those with damaged lateral and ventromedial prefrontal cortices—were even “better” than healthy adults in their decisions: their choices were more consistent with their initial ratings of the objects. <a href="https://blog.gsaneuro.com/editors/">Anastasia Glushko</a> interviewed Avinash for the NeuroBlog and wrote up the main points of their discussion – enjoy!</p>
</blockquote>

<hr />

<h2><i>On the role of the dorsomedial frontal cortex: valuing the alternatives</i></h2>

<p><strong>A (Anastasia): You suggest in the article that the dorsomedial PFC serves to “maintain the value of unattended options”. Is this mechanism specific for fixation-based updating or does the dorsomedial PFC prevent any external cues from completely “overwriting” our initial value ratings?</strong></p>

<p><strong>AV (Avinash):</strong> I do not think that the role of the dorsomedial frontal lobe in maintaining unattended values is specific to fixation-based value updating. Recent work has examined the role of this region in more ethologically relevant settings, namely in tasks where subjects must decide between ‘exploiting’ available choices and ‘foraging’ for alternative options. These studies have argued that this area has a role in representing the ‘value of foraging’ or the value of alternative decision options in the environment. Similarly, fixations provide a means for exploring, or foraging, in the visual environment. The dorsomedial PFC might help optimize this process by maintaining the values of options that are not currently being attended to. or fixated upon, ensuring that decisions reflect a balance between what is present in the environment, and what is immediately available or currently being attended.</p>

<table>
  <tbody>
    <tr>
      <td><img src="/assets/images/avinash1.png" width="80%" /></td>
    </tr>
  </tbody>
</table>

<hr />

<h2><i>How frontal lobe damage might affect valuation of naturalistic stimuli</i></h2>

<p><strong>A: You propose that the individuals with ventromedial PFC damage may use different attributes or weigh the attributes differently while assessing value (and this causes them to make “more rational” decisions than the control group). What are the object qualities that are “ignored” or weighted differently in this case?</strong></p>

<p><strong>AV:</strong> A recent study from our lab (<a href="http://www.jneurosci.org/cgi/content/long/35/22/8507">Xia et al., 2015, J.Neurosci</a>) examined this question in the domain of political decision-making. Chenjie Xia, a neurologist working in our lab, examined how the subjective attractiveness and competency of real-life political candidates were reflected in the choices of healthy subjects and subjects with frontal lobe damage in a mock ‘vote.’ Subjects with ventromedial frontal damage used information about the subjective attractiveness of candidates in their voting decisions, just like healthy controls and subjects with frontal lobe damage sparing this area. However, unlike these latter groups, the voting decisions of subjects with ventromedial frontal damage were not influenced by subjective assessments of competency. These results suggest that ventromedial frontal damage affects the weighting of some attributes during valuation, but not others. In particular, weighting of ‘higher-level’ attributes that require more social judgment—such as competency—might be affected by damage to this area, but not other ‘low-level’ attributes. We are currently working on a re-analysis of data from our Nature Communications study to test if ventromedial frontal damage also affected the weighting of aesthetic attributes during value judgment for the artwork stimuli that subjects were asked to rate. Stay tuned to find out…!</p>

<hr />

<h2><i>On the relationship of demographics with value judgment consistency and the underlying brain circuitry</i></h2>

<p><strong>A: You mentioned that the consistency of ratings in the control group was related to age and education. What is the nature of this relationship?</strong></p>

<p><strong>AV:</strong> Increased age and lower education were weakly associated with lower test-retest reliability in healthy subjects’ value ratings. The neural mechanisms underlying this individual variability are not very clear. While there is data suggesting that the ventromedial PFC has some role in controlling the variability of value judgment and value-based choice, we found that damage to this region did not affect the test-retest reliability of value ratings in this study. It is possible that other brain systems (i.e. other intact areas encoding subjective value information) might have helped our subjects with ventromedial PFC damage compensate for this increased variability in value judgment. Alternatively, differences in the measurement of value judgment reliability in this study and past studies could also explain these findings. In either case, these findings open up many questions about the critical contribution of ventromedial PFC for this type of generic value judgment.</p>

<table>
  <tbody>
    <tr>
      <td><img src="/assets/images/avinash.png" width="80%" /></td>
    </tr>
    <tr>
      <td><em>Avinash in Toronto with one of <a href="http://www.brainproject.ca/">The Brain Project’s</a> sculptures</em></td>
    </tr>
  </tbody>
</table>

<hr />

<h2><i>Future directions and the importance of patient studies</i></h2>

<p><strong>A: How far do you think we are from understanding the neural network underlying value-based decision making? And what is the role of patient studies in this type of research?</strong></p>

<p><strong>AV:</strong> There is a long way to go. There is some agreement as to which key brain regions are involved in value-based decisions, generally speaking. However, the basic neural mechanisms underlying decision behavior, and the specific contributions of these regions, are still heavily disputed. Studies of focal brain damage in patient populations have a lot to offer to this field (and to cognitive neuroscience more generally!), as this method remains the best-established way to test the necessity of a brain region for a behavior of interest. As a causal test, human lesion studies have an important complementary role to correlative measures like functional neuroimaging and electrophysiology, and also provide a bridge to work in animal lesion models.</p>

	  ]]></description>
	</item>

	<item>
	  <title>From 1D to 2D in the electrophysiology of the human retina&#58; an interview with Mathieu Gauvin</title>
	  <link>//2016/05/26/mathieu-gauvin-ipn-interview/</link>
	  <author></author>
	  <pubDate>2016-05-26T15:01:00-04:00</pubDate>
	  <guid>//2016/05/26/mathieu-gauvin-ipn-interview/</guid>
	  <description><![CDATA[
	     <blockquote>
  <p>Our new interview is with <a href="https://scholar.google.ca/citations?hl=en&amp;user=rb7UxjQAAAAJ" target="_blank">Mathieu Gauvin</a>, Ph.D. student supervised by <a href="http://www.thechildren.com/departments-and-staff/staff/pierre-lachapelle-phd-director-visual-electrophysiology" target="_blank">Dr. Pierre Lachapelle</a> at the McGill Visual Electrophysiology Laboratory and Clinic. Mathieu works on the development of new methods for studying retinal function to better understand both normal and impaired visual processing. His findings (<a href="http://www.ncbi.nlm.nih.gov/pubmed/26746684" target="_blank">published in the Journal of Vision</a>) show how using some cutting-edge techniques when analyzing the human electroretinogram can uncover distinct markers of different types of retinal impairment. In a Q&amp;A session with <a href="https://blog.gsaneuro.com/editors/">Anastasia Glushko</a>, Mathieu told us about his project and its clinical potential!</p>
</blockquote>

<hr />

<p><strong>A (Anastasia): Hi, Mathieu! Thanks again for agreeing to answer our questions. Can you tell us in a couple of sentences what the main goal of your PhD research is?</strong></p>

<p><strong>M (Mathieu):</strong> As you might know, to study retinal function, scientists and clinicians rely on the electroretinogram (ERG), which is the electrical signal that is generated by the retina following a light stimulus. Of interest, the ERG was the first biopotential ever recorded (by Dewar in 1877) from a human subject. In the last 100 or so years, the recording technologies were tremendously improved, but the analysis of the ERG remained limited to the basic time domain measurement of its <em>amplitude</em> and <em>latency</em>.</p>

<p>When I started my PhD project, Dr. Lachapelle, who is the head of the McGill Visual Electrophysiology Clinic and Laboratory, asked me: “Is it possible to modernize the ERG analysis in order to bring it to the 21st century?” I told him “Yes!” and it became the goal of my PhD project! To do so, I have used some of the most up-to-date signal processing techniques (many of which were developed in the laboratory of my co-supervisor, <a href="https://scholar.google.ca/citations?user=pYbiAC8AAAAJ"><em>Dr. Jean-Marc Lina</em></a>) to analyze normal and pathological ERGs. My project thus addressed an important question: «Can advanced analytical approaches uncover additional useful information from ERG recordings?». Specifically, I undertook to complement the classical time domain analyzes of amplitude and latency of ERG responses with the investigation of the <em>oscillation</em> <em>frequencies</em> underlying different ERG components. Indeed, my findings showed that studying the time-frequency domain could significantly improve our basic understanding of the ERG and its clinical usefulness.</p>

<table>
  <tbody>
    <tr>
      <td><img src="/assets/images/mathieu.png" width="80%" /></td>
    </tr>
    <tr>
      <td><em>Mathieu working through his last datasets</em></td>
    </tr>
  </tbody>
</table>

<hr />

<p><strong>A: This sound really exciting! I have a question now about the specific types of ERG responses you analyzed. You used the discrete wavelet transform to measure the oscillation frequencies contributing to the a- and b-wave responses in the ERG. What do these two types of waves stand for?</strong></p>

<p><strong>M:</strong> In your retinas, your photoreceptors capture incoming photons (i.e. light) and convert this energy into electrical responses that subsequently activate other specialized retinal cells (e.g., bipolar cells, Müller cells, etc.), ultimately leading to the transmission of visual information to the brain via the optic nerve. Therefore, following a light stimulus, a sequence of bioelectrical retinal events can be measured non-invasively with an electrode located on the eye (e.g., the cornea) or close to it (e.g., the eye lid or temple). The signal thereby obtained represents the ERG. The a- and b-waves are simply the two main (i.e., biggest) waves of the ERG waveform (see Figure 1A). The a-wave is the first negative deflection (mostly reflecting the activity of the photoreceptors) and the b-wave is the second positive wave (which accounts mostly for the activity of bipolar and Müller cells).</p>

<table>
  <tbody>
    <tr>
      <td><img src="/assets/images/mathieu-data.png" width="80%" /></td>
    </tr>
    <tr>
      <td><em>Figure 1</em></td>
    </tr>
  </tbody>
</table>

<hr />

<p><strong>A: I see. And as far as I’ve understood, you found that independent processes (“sub-components” of the b-wave) operate in different frequency bands of the ERG, right? What is the distinct contribution of each frequency band? Are these mechanisms elicited by different cell types?</strong></p>

<p><strong>M:</strong> We found that in normal individuals, the main components of the ERG b-wave oscillate in the 20Hz and 40Hz frequency bands. These frequency components were thus termed 20b and 40b, respectively. These two descriptors were differently modulated by the same light stimuli, suggesting that these two processes are independent. Moreover, 20b and 40b contribute differently to different types of retinal pathway anomaly: in the ON retinal pathway anomaly we found a marked reduction of the 20b, whereas the OFF retinal pathway anomaly revealed a severe reduction of the 40b. Because we know that patients affected with ON or OFF pathway anomaly have a conduction deficit that prevents their ON or OFF bipolar cells to be stimulated, these two frequency components might be linked to neuroanatomy (e.g., to the ON and OFF bipolar cells). To confirm this assumption, one would need to use pharmacological blockade of ON and OFF bipolar cells; but, irrespective of this confirmation, we showed that the discrete wavelet transform reveals reproducible, physiologically meaningful, and diagnostically relevant descriptors of the ERG over a wide range of signal amplitudes and morphologies.</p>

<hr />

<p><strong>A: Does that also mean that your results are potentially clinically applicable? In general, what is the clinical relevance of ERGs, and how could your findings change the status quo (i.e., regarding assessments of visual impairments)?</strong></p>

<p><strong>M:</strong> Currently, examination of the retina with the ophthalmoscope is one of the most widespread clinical exams. Furthermore, the normal function of any retinal cells can be changed by numerous pathological processes – and, as a result, these functional changes will alter the amplitude and/or timing of some ERG components (see figure 1B). Given that the ophthalmoscope does not always reveal signs of the suspected retinopathy on the retina, the ERG is often considered to be a more objective diagnostic tool. Unfortunately, amplitude and peak-time measurements of the ERG have some significant diagnostic limitations, which might explain the lower popularity of this clinical test. This is better illustrated in Figure 1B where four pathological ERGs, which are similarly reduced in terms of amplitude, present with strikingly different morphologies. Using the traditional analysis approach (e.g., amplitude of the b-wave), these ERG waveforms would all be classified in the «reduced amplitude» category and are thus all considered to be equivalent. Our latest study suggests that the use of the discrete wavelet transform will be useful to distinguish between the ERGs that previously were erroneously considered as equivalent using the traditional approach. Specifically, we could segregate ERGs recorded from patient affected with diseases that specifically alter the function of the ON and OFF cone pathway. Our findings suggest that the analysis of the ERG using the discrete wavelet transform is a valuable addition to the electrophysiologist’s armamentarium that has an immense potential for improving the quantification and interpretation of normal and pathological ERG responses.</p>

	  ]]></description>
	</item>

	<item>
	  <title>Interview with Emily Coffey</title>
	  <link>//2016/04/27/emily-coffey-ipn-interview/</link>
	  <author></author>
	  <pubDate>2016-04-27T15:01:00-04:00</pubDate>
	  <guid>//2016/04/27/emily-coffey-ipn-interview/</guid>
	  <description><![CDATA[
	     <blockquote>
  <p>Finally, we are starting to post interviews with our fellow graduate students in neuroscience at McGill! The first Q&amp;A session we held was with Emily Coffey, Ph.D. student in <a href="http://www.zlab.mcgill.ca/home.php" target="_blank">the lab of Dr. Robert Zatorre</a>. Earlier this year, Emily’s <a href="http://www.nature.com/ncomms/2016/160324/ncomms11070/full/ncomms11070.html" target="_blank">first-authored article based on her magnetoencephalography (MEG) investigation of the auditory frequency-following response</a> (FFR) was published in Nature Communications. In their study, Emily and her colleagues showed that the FFR, a neurophysiological response to complex periodic sounds previously considered to be of purely subcortical origins, may in fact partially reflect contributions from the human auditory cortex. In other words, the use of MEG (instead of the electroencephalography, typically used for studying auditory brainstem responses) allowed the authors to see that the auditory cortex works together with the brainstem during sound periodicity analysis. NeuroBlog editor <a href="https://blog.gsaneuro.com/editors/" target="_blank">Anastasia Glushko</a> spoke to Emily about this study, and we hope you’ll enjoy reading what came out of this conversation!</p>
</blockquote>

<hr />

<p><strong>A (Anastasia): To start from the basics, I wanted to ask you about the collaboration of the brainstem and the auditory cortex (AC) during sound periodicity analysis. You mention in the article that the connection between these two brain regions can potentially work in both directions. On the one hand, the signals from the brainstem can be transferred to the auditory cortex. But the auditory cortex might also influence the brainstem when fine-grained analysis of sound frequency is performed. What do you think could be the functionality of these two directions of the information flow (also taken into account that the AC seems to be activated later than the subcortical structures during sound frequency processing)?</strong></p>

<p><strong>E (Emily)</strong>: We know from anatomical work that there are a lot of descending projections in the auditory system (in fact more than ascending projections), but we don’t yet know too much about how lower and higher level areas work together to process sound. This is one of the things we are currently trying to understand about how the auditory system works, and what our new MEG technique will hopefully be useful for.</p>

<p>Interestingly, early signals can be influenced by many things like what you’re listening to, whether the sound is played forwards or backwards, or whether or not you know how to speak a tonal language, like Mandarin. Those observations suggest involvement of higher-level processes like selective attention, but as you point out, these these effects often cannot be an <em>elicited</em> response to sound because of the timescales involved - the signal cannot have made it up to the cortex and then back down to the brainstem again in that short an interval of time. This suggests that top-down processes have either acted on the lower parts of the system to change how they process incoming sound in a relatively permanent fashion (as in the case of long-term music or language experience), or they might be acting to filter sound in an online temporary fashion, like when you direct your attention to one person talking in a crowded restaurant.</p>

<p>The brain signals we’re working with can also be elicited when people are sleeping or awake but distracted doing something else. This is perhaps a good measure of the feed-forward part of the signal, since processes like selective attention are not engaged, but it still could of course have been influenced by long-term training.</p>

<p>Sound is a very complex and rich source of information, and the brain seems to have evolved “built-in” ways of separating and manipulating it, the ability to tune and change those mechanisms over long periods of time, and the capability of voluntarily modifying incoming signals according to task demands. How well the information is preserved as it comes in and is then filtered, enhanced and processed by higher-level systems in turn affects the quality of information that is sent on for purposes like language processing. We have a lot of work to do to figure out how all this takes place!</p>

<hr />

<p><strong>A: The AC activations in your study were right lateralized. This is in line with the often reported differences in the functionality of the left and right ACs. The right AC seems to be relatively specific for fine-grained sound frequency analysis while the left AC is “better” at temporal resolution. In the article, you mention the possibility that the computations on the brainstem level might contribute to the asymmetry in the AC. Does this mean that certain processes in the brainstem might have lead to the fact that left hemisphere is more tuned for language processing (which normally requires better temporal resolution than music perception)?</strong></p>

<p><strong>E</strong>: A lot of processing does go on at the level of the brainstem in the auditory system. Given the level of top-down connectivity, it wouldn’t surprise me if signal frequency specialization was already beginning in these lower areas. However, I don’t think we can say much about how this contributes to the cortical lateralization we see here in humans, from this technique. Although we can differentiate between signals from the left and right cortex and different levels of the brainstem, the pairs of brainstem nuclei are close together and deep, so they will be difficult to resolve using non-invasive methods.</p>

<hr />

<p><strong>A: It is exciting that the research on auditory brainstem responses has clear clinical potential. You write in the article that certain FFR parameters are reliable biomarkers of some clinical syndromes. What are the existing and/or potential applications of FFR measures in clinical practice? And how does the finding of the cortical component in the FFR contribute to fields where measures of auditory brainstem responses are used in clinical settings?</strong></p>

<p><strong>E</strong>: The frequencies observed using the FFR are important for how we perceive the pitch and timbre of sounds. Many problems that have language-related components show differences in the FFR, suggesting that there are abnormalities or deficiencies in how sound is processed. These include autism, language-related learning disorders, and deciphering speech in noisy conditions in older people and in children. The FFR could be used to identify sub-classes of populations that might benefit from a certain kind of treatment and to track improvements in the FFR and behavior over time. There is also evidence to suggest that music practice enhances the FFR and mitigates some of these problems, which would certainly make for an enjoyable treatment solution! The work on FFRs as biomarkers and as measures of treatments is still in development (<a href="http://brainvolts.northwestern.edu" target="_blank">Prof. Nina Kraus’s lab</a> at Northwestern University is doing some very interesting work on these topics).</p>

<p>The finding of a cortical component to the FFR is I think most relevant on the research side. I doubt we’ll be measuring people’s cortical MEG-FFR responses in the clinic because EEG is far cheaper and more practical! But I hope it will be useful to better understand what the EEG signal means, where it comes from, and which brain regions are at fault when poor auditory system function is contributing to clinical problems.</p>

	  ]]></description>
	</item>

